# AUTOGENERATED! DO NOT EDIT! File to edit: 05_Feature_DBPedia_EntityResolution.ipynb (unless otherwise specified).

__all__ = ['nlp', 'dbpedia_response', 'EnitityLinkVisitor']

# Cell
import requests
import json
import spacy
from typing import List, Tuple
from .article import Article, Features
from .common import ArticleVisitor, TextCleaningVisitor

nlp = spacy.load("en_core_web_sm")


# Cell
def dbpedia_response(text: str, url: str = "https://api.dbpedia-spotlight.org/en/annotate",
                     entities: str = ["Person", "Organisation", "Place"]) -> Tuple[List[Tuple[str, str, float]], set]:
    """
    The dbpedia_response function accepts a document as a string and then divides it into
    sentences as the dbpedia api doesn't support large text annotations.

    Also it takes the rest api URL for DBpedia Spotlight and a list of entities that we need to
    search for from a dictionry which can passed as a part of the config

    It annotates the article text sentence by sentence based on the pretrained dbpedia model
    and identifies the words of importance and obtains the dbpedia uri,similarity score etc for the word

    The function

    Parameters:
    -----------
    text: str,
        The documents which needs to be annotated
    config_dict: dict,
        The dictionary containing the parameters for creating the resp api request.
        It has two keys
        url: str,
            The dbpedia rest api URL
        entities: list,
            The list of entities that we will try to annotate for. We pass all the entities together


    Returns:
    --------
    extracted_tuples: list,
        The list of tuples which contains the dbpedia uri, the exact word that it resolved, the similarity score
        for all the annotated words in the document
    extracted_uri: list,
        The unique list of URIs for the words that got annotated. It is an extention of the earlier tuples list
        for downstream application

    """

    doc = nlp(text)
    sentences_list = [sent.string.strip() for sent in doc.sents]
    extracted_tuples = []
    extracted_uri = []
    for sent in sentences_list:
        # parameters for the request.get is created for each sentence
        payload = {'text': sent, 'types': ",".join(
            entities)}
        # presently we are annotating only person organization and place
        headers = {'accept': 'application/json'}
        r = requests.get(url, params=payload, headers=headers)
        if 'Resources' in json.loads(r.content):
            output = json.loads(r.content)["Resources"]
            for val in output:
                extracted_tuples.append(
                    (val["@URI"], val["@surfaceForm"], val["@similarityScore"]))
                extracted_uri.append((val["@URI"]))

    return extracted_tuples, set(extracted_uri)


# Cell
class EnitityLinkVisitor(ArticleVisitor):
    """
    This class is a concrete implementation of a visitor pattern.
    This implementation makes sure that any tokens in entity name are not part of extracted PERSON/ORG tuples.
    """

    def __init__(self) -> None:
        """
        the initialization function to initialize the class

        Returns:
        ---------
        feature_class:
            Initialized class
        """
        super().__init__()

    def visit_article(self, article: Article) -> None:
        """
        The visit article get the initialized article and then created the feature named by the field_name
        which is passed in the parameter.

        It obtains the article text and then then calls text cleaner function to remove the HTML tags
        Then in annotates the text using dbpedia_response function and returns the extracted entities
        which are a list of tuples and URIs obtained from the annotated text

        Parameters
        ----------
        article: Article
            The initialized article class from which the feature needs to be extracted

        Returns
        -------
        None
        """
        article.accept_visitor(TextCleaningVisitor())
        clean_text = (list(article.extracted_entities.items())[0][1])
        extracted_tuples, extracted_uri = dbpedia_response(
            clean_text)
        article.extracted_entities[Features.DBPEDIA_ENTITY_TUPLES] = extracted_tuples
        article.extracted_entities[Features.DBPEDIA_ENTITY_URI] = extracted_uri
